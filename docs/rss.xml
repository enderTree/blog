<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>ender'Blog</title><link>https://enderTree.github.io/blog</link><description>闭关</description><copyright>ender'Blog</copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://github.githubassets.com/favicons/favicon.svg</url><title>avatar</title><link>https://enderTree.github.io/blog</link></image><lastBuildDate>Wed, 25 Jun 2025 07:53:07 +0000</lastBuildDate><managingEditor>ender'Blog</managingEditor><ttl>60</ttl><webMaster>ender'Blog</webMaster><item><title>MaxCompute外表使用</title><link>https://enderTree.github.io/blog/post/MaxCompute-wai-biao-shi-yong.html</link><description>### 1. 建表
1. json格式

```sql
CREATE EXTERNAL TABLE IF NOT EXISTS dialogue.dwd_ext_xingye_log_chatml_data(
    `data` STRING
) 
PARTITIONED BY (
    data_type STRING,
    ymd STRING) 
ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe' 
STORED AS INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' 
OUTPUTFORMAT 'org.apache.hadoop.mapred.TextOutputFormat' 
LOCATION 'oss://data-dlc/minimax-dialogue/data/chatml/';
```

2. parquet格式
   ```sql
   CREATE EXTERNAL TABLE dwd_crawler_html_out_di
   (
      url string,
       html string,
       source_tag string,
       lang string
   )
   partitioned BY (ymd string)
   stored AS parquet  
   location 'oss://data-dlc/minimax-dialogue/data/chatml/data_type=html_data/';
   ```
3. 自定义解析器
```sql
CREATE EXTERNAL TABLE ods_crawler_sites_warc_data_extract_result_external_hi (
    warc_host string,
    meta_info string,
    final_url string,
    status_code string,
    data_dt string,
    biz_code string,
    target_url string,
    warc_date string,
    content_type string,
    content_length string,
    warc_file_name string,
    content string,
    import_msg string
)
PARTITIONED BY (
    host string,
    status string,
    ymd string,
    hour string
)
stored BY 'com.crawler.udf.sites_warc.WarcStorageHandler' 
with serdeproperties (
    'max_file_size' = '157286400'
) 
LOCATION 'oss://crawler-data-storage/Crawlerlee/'
USING 'crawler_udf-1.0-SNAPSHOT.jar'
```
可参考这篇文章

### 2. 使用
1. 插入数据
```sql
SET odps.sql.unstructured.oss.commit.mode = true; -- 防止生成.odps文件夹
INSERT OVERWRITE TABLE dwd_crawler_html_out_di PARTITION(ymd='${P_DATE}')
SELECT 
    a.source_url,
    html,
    biz_code,
    parse_lang
FROM 
    dwd_crawler_content_filtered_detail_byscore_di a
WHERE 
    a.ymd = '${P_DATE}'
    AND a.score_level != 'low'
    AND COALESCE(html, '') != ''
```
2. 读取数据
```
-- 扫描所有路径
msck TABLE ods_crawler_sites_warc_data_extract_result_external_hi ADD partitions;
-- 扫描指定路径
ALTER TABLE ods_crawler_sites_warc_data_extract_result_external_hi ADD IF NOT EXISTS 
PARTITION (host='demo.com',status='error',ymd='20250624', hour='09') 
PARTITION (host='demo.com',status='success',ymd='20250624', hour='09')
;
-- 指定location
ALTER TABLE log_table_external ADD PARTITION (year = '2016', month = '06', day = '01')
location 'oss://oss-cn-hangzhou-internal.aliyuncs.com/bucket名称/oss-odps-test/log_data_customized/2016/06/01/';
-- 指定路径映射
MSCK REPAIR TABLE  ods_crawler_sites_warc_data_extract_result_external_hi ADD PARTITIONS
WITH PROPERTIES ('odps.msck.partition.column.mapping'='host:host,status:status,ymd:ymd');
```。</description><guid isPermaLink="true">https://enderTree.github.io/blog/post/MaxCompute-wai-biao-shi-yong.html</guid><pubDate>Wed, 25 Jun 2025 07:38:39 +0000</pubDate></item><item><title>表命名规范</title><link>https://enderTree.github.io/blog/post/biao-ming-ming-gui-fan.html</link><description>
### 1. 数仓分层
按 ods -&gt; dwd -&gt; dwm -&gt; dws -&gt;ads 来做
- dwd：事实级别的明细，或者did uid级的数据。</description><guid isPermaLink="true">https://enderTree.github.io/blog/post/biao-ming-ming-gui-fan.html</guid><pubDate>Wed, 25 Jun 2025 07:30:17 +0000</pubDate></item><item><title>全局排序优化</title><link>https://enderTree.github.io/blog/post/quan-ju-pai-xu-you-hua.html</link><description>```sql

CREATE TABLE talkie_dialogue.tmp_nana_data_1028_555 AS 
WITH hash_bucket AS (
    SELECT  
        *,
        ROW_NUMBER() OVER (PARTITION BY bucket_no ORDER BY user_msg_log_ucnt_30d ASC ) AS bucket_rel_index,
        COUNT(1) OVER (PARTITION BY bucket_no ) AS bucket_size
    FROM    
    (
        SELECT  
            *,
            ABS(HASH(cid)) % 100000 AS bucket_no 
        FROM    
            talkie_dialogue.tmp_nana_data_1028_4            
    ) 
),
bucket_base AS 
(
    SELECT
        bucket_no
        SUM(bucket_size) OVER (ORDER BY bucket_no ASC) - bucket_size AS bucket_base
    FROM
    (
        SELECT 
            bucket_no,
            bucket_size
        FROM
            hash_bucket
    )
)
SELECT
    /*+ MAPJOIN(t2) */ t1.*,
    t2.bucket_base + bucket_rel_index AS id_index
FROM
    hash_bucket t1 
JOIN 
    bucket_base t2 
    ON t1.bucket_no = t2.bucket_no
    AND t1.mid_rank = t2.mid_rank
    AND t1.country_rank = t2.country_rank
    AND t1.setting_type = t2.setting_type
;
```

核心代码如上，主要思路先做分桶进行分布式局部排序、再基于桶大小得到全局索引

1. 第一步先对id做hash分桶，然后计算每个桶的大小，桶数量可以根据需要计算的id数量来评估，这里分100000个桶，然后计算出每个id在桶内的相对位置bucket_rel_index，同时计算出桶大小bucket_size；
2. 第二步根据桶大小计算每个桶的基址；
3. 第三步将桶基址+id在桶内的相对地址得到全局唯一的绝对地址id_index；

。</description><guid isPermaLink="true">https://enderTree.github.io/blog/post/quan-ju-pai-xu-you-hua.html</guid><pubDate>Wed, 25 Jun 2025 03:39:22 +0000</pubDate></item><item><title>解决Join数据倾斜</title><link>https://enderTree.github.io/blog/post/jie-jue-Join-shu-ju-qing-xie.html</link><description>优化前：
```sql
SELECT 
        /*+ mapjoin(dd),skewjoin(a(url))*/
        a.* except(url_tag, join_key),
        CASE 
            WHEN cc.url IS NOT NULL THEN 'black_url'
            WHEN dd.url IS NOT NULL THEN 'black_url'
            ELSE ''
        END AS url_tag
    FROM
    (
        select 
            *,
            1 AS join_key
        from 
            dwd_crawler_urls_step1_di a 
        where 
            ymd = '${P_DATE}'
            AND url_tag != 'black_url'
    ) as
    LEFT JOIN 
        black_urls2 cc  
        ON replace(a.host, 'www.', '') = replace(cc.url, 'www.', '')
	LEFT JOIN 
        black_urls1 dd  
        ON INSTR(a.url, dd.url) &gt; 0
```
优化后
```sql
SELECT 
        /*+ mapjoin(dd),skewjoin(a(url))*/
        a.* except(url_tag, join_key),
        CASE 
            WHEN cc.url IS NOT NULL THEN 'black_url'
            WHEN dd.url IS NOT NULL THEN 'black_url'
            ELSE ''
        END AS url_tag
    FROM
    (
        select 
            *,
            1 AS join_key
        from 
            dwd_crawler_urls_step1_di a 
        where 
            ymd = '${P_DATE}'
            AND url_tag != 'black_url'
    ) a
    LEFT JOIN 
        black_urls1 dd  
        ON INSTR(a.url, dd.url) &gt; 0
    LEFT JOIN 
        black_urls2 cc  
        ON replace(a.host, 'www.', '') = replace(cc.url, 'www.', '')
```
优化前执行时间

&lt;img width='991' alt='Image' src='https://github.com/user-attachments/assets/3d62cdfd-b1e0-4579-adc9-a8bc19ac64ff' /&gt;

&lt;img width='872' alt='Image' src='https://github.com/user-attachments/assets/46033d2f-9fbe-4400-b6c6-489f97ee7f00' /&gt;

优化后执行时间

&lt;img width='978' alt='Image' src='https://github.com/user-attachments/assets/74de5fc3-08ff-4ed6-8c94-9b0d31c18799' /&gt;

&lt;img width='944' alt='Image' src='https://github.com/user-attachments/assets/b2f397da-420d-484b-9655-3dda6ee57046' /&gt;
。</description><guid isPermaLink="true">https://enderTree.github.io/blog/post/jie-jue-Join-shu-ju-qing-xie.html</guid><pubDate>Wed, 25 Jun 2025 03:39:03 +0000</pubDate></item><item><title>窗口函数的一些使用</title><link>https://enderTree.github.io/blog/post/chuang-kou-han-shu-de-yi-xie-shi-yong.html</link><description>#### 1. 取最近一个不为空的值填充
```sql
WITH mian_data AS (
    SELECT
        c0,
        c1,
        IF(c1 = '处置', NULL, c2) AS c2
    FROM
        VALUES
         (1,'处置','1')
        ,(2,'处置','2')
        ,(3,'处置','3')
        ,(4,'处置','4')
        ,(5,'提交','A')
        ,(6,'处置','5')
        ,(7,'提交','b')
    AS a(c0,c1,c2)
)
SELECT 
    *,
    FIRST_VALUE(c2, True) over(order by c0 ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)
FROM 
    mian_data 
```。</description><guid isPermaLink="true">https://enderTree.github.io/blog/post/chuang-kou-han-shu-de-yi-xie-shi-yong.html</guid><pubDate>Wed, 25 Jun 2025 03:38:36 +0000</pubDate></item><item><title>test</title><link>https://enderTree.github.io/blog/post/test.html</link><description>```sql

SELECT
    *
FROM
(

    SELECT
        tag,
        doc_cnt,
        (doc_cnt/SUM(doc_cnt) OVER())*100
    FROM
    (
        SELECT 
            tag,
            SUM(doc_cnt) AS doc_cnt
        FROM
            dwd_crawler_host_classification_di a
        LEFT ANTI JOIN 
            tmp_gumu_data_0624_2 b
            ON a.host = b.host
        WHERE
            ymd = '2025-06-23'
            AND tag_type = 'topic'
        GROUP BY 
            tag
    )
)
WHERE 
    tag = 'Advertising_&amp;_Marketing'
;
```。</description><guid isPermaLink="true">https://enderTree.github.io/blog/post/test.html</guid><pubDate>Wed, 25 Jun 2025 02:50:59 +0000</pubDate></item></channel></rss>